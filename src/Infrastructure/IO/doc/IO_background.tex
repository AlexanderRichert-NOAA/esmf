% $Id: IO_background.tex,v 1.12 2002/05/10 20:36:39 lzaslavsky Exp $


Earth system modeling applications require efficient and robust tools
for input and output of structured andf unstructured gridded data, as
well as observational data streams.  Interfaces and methods provided
by ESMF should allow reading and writing of data in several standard
formats as well as support efficient internal data representations
(see ESMF General Requirements \cite{ESMFGenReq}, Section 8.1.3). 
The ESMF IO is supposed to provide a unified interface to input and output 
of high level ESMF objects such as Fields.  The system is expected to 
automatically detect file formats at runtime, and to output data in a variety 
of formats, with the posibility of creating companion metadata files. Other 
file IO functionalities, such as writing of error and log messages and input 
of configuration parameters from an ASCII file, are not covered in this
document. 
%%Arlindo%%%%
%%These will be the subject of the Log Utility and Configuration Parameter 
%%requirement documents.
%%Arlindo%%%%
These will be the subject of the ESMF Log Requirement Document and the ESMF 
Control Requirement Document \cite{ESMF-Log-Req, ESMF-Control-Req}.


\subsection{I/O architecture}

We use the experience of the WRF \cite{WRF-Software} and FMS 
\cite{Balaji_Parallel_IO_2000}  projects in defining the 
ESMF I/O architecture that is efficient, flexible, end-to-end, and package 
neutral. Our principles will be:

\begin{description}
\item[-] Define a standard unified I/O interface and API covering 
         ESMF-supported data models.
\item[-] Provide efficient implementation of this API for multiple data 
         formats supported by the ESMF. 
\end{description}



\subsection{Data Models}

Earth system models use a variety of discrete grids to maintain information 
about fields in continuous space, as well as observations. The primary ESMF 
codes employ finite-difference and finite-volume grids, spectral grids, 
unstructured land-surface grids, and ungridded observational networks.

Fields within a model component are frequently defined on the same
physical grid and are decomposed in memory in an identical fashion;
that is, they share a distributed grid. They form a {\em bundle of
fields} defined on the same distributed grid. The gridded data are
supported by three ESMF elements: {\em PhysGrid} element 
for phyical grids, {\em DistGrid} element for distributed grids, and 
{\em Fields} class for fields (\cite{ESMF-PhysGrid-Req},
\cite{ESMF-DistGrid-Req}, \cite{ESMF-Field-Req}). 

ESMF I/O will support the following three models of data: 
\begin{description}
\item[\bf Regular Gridded Data] The data of this kind are defined on a
logically rectangular grid. Multi-dimensional arrays can be used for
storing the data and operating. The neighbor relationships are defined
naturally by geometry.

\item[\bf Data on Unstructured Grid] The data of this kind are defined on an 
irregular grid such as in Finite-Element Methods. A list of neighbors should 
be explicitly provided for each grid node. 

\item[\bf Observational Data] The data of this kind describe the 
measurements. Each observation is associated with a a spatial point or region.
A neighbor relationship is not defined for observations. 
\end{description}

As we have already mentioned, logically rectangular grids are naturally 
represented by multi-dimensional arrays. The two latter data models can be 
represented as one-dimensional arrays of structures with each structure 
containing information about location, field values associated with this 
location, and a list of neighbors, if relevant. 

\subsection{Metadata. ESMF metadata conventions}

{\bf Metadata} is data about a digital object, ``structured data about the 
data''. The metadata is usually provided by the creator or distributor of 
the object, and often either accompanies the object or is embedded in the 
file header. As such, metadata can be very useful as the basis for 
information storage and retrieval systems, as well as for utilization of the 
data within Earth Science models.
The information about the object provided by metadata allows to optimize  
resource allocation and organization of storage and retriaval of data. In 
parallel computing, such a knowledge may be especially important. 

If metadata are provided, the files may be either {\em self-described} or
{\em co-described}, depending on the fashion how metadata are allocated.
\begin{description}
\item[\bf A self-described file] contains in its header all metadata 
necessary to provide a unique interpretation of the file content
assuming certain conventions.  
\item[\bf A co-described file] is accompanied by a metadata file. The
metadata file provides a unique interpretation of the data file content
under certain conventions. 
\end{description}
It is assumed the metadata can be rapidly read by a corresponding API without 
reading an entire content of the data file. Some data files may contain 
complete description of their content, but the way data are represented might 
not allow rapid extraction of metadata. To make such a file co-described, its 
metadata could be extracted and allocated to a companion metadata file.

Some file formats that we discuss bellow, such as NetCDF and HDF, are 
organized according to well-defined rules. Their structures and APIs enable 
(but do not require) creation of self-described files. By narrowing 
the defintions, conventions enable a complete and unique description of each 
dataset.

We assume that the NetCDF conventions for climate and forecast metadata, 
``CF conventions'', will serve as a a basis for ESMF metadata conventions.
 NetCDF Climate-Forecast Metadata Conventions
\cite{NetCDF_CF_v1_beta3} narrow definitions of NetCDF, an
array-oriented data format and a library for gridded data 
\cite{NetCDF3_UsersGuide_C} to allow a unique and complete description
of gridded data used in geoscience. CF conventions specify standard 
dimensions, such as date or time ({\t t}), height or depth ({\it z}), 
latitude ({\it y}), and longitude ({\it x}), and specify standard
units for these dimensions and other quantities. 

%%% Leonid %%%
%%% We expect ESMF metadata conventions to be defined as extensions to
%%% CF-conventions covering fields defined on both structured and unstructured 
%%% grids, and observational data. Such conventions have to be accepted by all 
%%% participants of the ESMF project.
%%% Leonid %%%

We expect ESMF metadata conventions to be defined as extensions to
CF-convention s covering fields defined on both structured and
unstructured grids, as well as observational data. Unlike the CF
conventions which are tightly associated with NetCDF, the ESMF
conventions are supposed to be format neutral, and conver all of the
ESMF data formats.  These extensions will become the ESMF standard,
and will be enforced by the ESMF I/O subsystem.

ESMF I\/O interfaces and software will cover only I/O of data covered by
the ESMF convention.




\subsection{Data Formats}



Several standard formats are currently used in Earth Science modeling
for input/output of data:

\begin{description}
\item[\bf NetCDF] Network Common Data Form (netCDF) is an interface for 
array-oriented data access. The netCDF library provides an
implementation of the interface. It also defines a 
machine-independent format for representing scientific data. Together,
the interface, library, and format support the creation, access, and
sharing of scientific data. The netCDF software was developed at the
Unidata Program Center in Boulder, Colorado. See \cite{NetCDF3_UsersGuide_C}.
In geoscience, NetCDF can be naturally used for represenation of fields 
defined on logically rectangular grids. NetCDF use in geosciences is 
specified by CF conventions mentioned above \cite{NetCDF_CF_v1_beta3}. 

To the extent that data on unstructured grids (or even observations) can be 
represented as one-dimensional arrays, NetCDF can also be used to store these 
data. However, it does not provide a high-level abstraction for this type of 
data. 

\item[\bf DODS] The Distributed Oceanographic Data System is a system that 
allows access to data over the internet. DODS is created and supported by 
Unidata Program Center in Boulder, Colorado. See \cite{DODS}. DODS enables an 
implementation of NetCDF-client libraries that permits remote access to data 
through the Internet.


\item[\bf HDF] The Hierarchical Data Format (HDF) project provides
interface,  software and file formats for scientific data management. 
The HDF software includes I/O libraries and tools for analyzing,
visualizing, and converting scientific data. 

HDF is developed and supported at the National Center for Supercomputing 
Applications, University of Illinois at Urbana-Champaign. There are two 
different HDF formats, HDF (4.x and previous releases) and HDF5. These 
formats are completely different and {\it not} compatible.  See
\cite{HDF4_tutorials}, \cite{HDF5_tutorial}.

HDF Scientific Data Sets API allows to efficiently operate with
multi-dimensional arrays. Although HDF SDS itself does not provide a way
to represent high-level abstractions for data on unstructured grids
and observational data sets, HDF-based applications, such as HDF-EOS
do so in HDF-EOS Point Point Structure.


%%Because of hierarchical nature of data representation, the HDF
%%interface and API may provide structural ways 
%%to represent data on structured and unstructured grids, as well as 
%%observational data. 


\item[\bf HDF-EOS]  The Hierarchical Data Format - Earth Observing
System (HDF-EOS) is the scientific data format standard selected by
NASA as the baseline standard for the Earth Observing System (EOS). HDF-EOS
is an extension of HDF and uses HDF library calls as its underlying
basis. Version 4.1r1 of HDF is used. The library and tools are written
in C language and a Fortran interface is provided. See \cite{HDF-EOS}.

HDF-EOS can be used for different data models within ESMF. Regular
gridded data are supported by HDF-EOS Grid Structures, while HDF-EOS  
Point Structure covers unstructured grid and observational data.

% \item[\bf GRIB] GRid in Binary (GRIB) format is a gridded data
% standard from the World Meteorological Organization. NCEP uses GRIB
% for all the files produced by its analyses. Unfortunately, not all
% GRIBs are the same and the ECMWF and EMC use slightly different
% formats, though they both claim to use GRIB. See \cite{GRIB_1}.  We
% expect GRIB files to be co-described, e.g., accompanied by a metadata
% file.  If metadata file is not provided, necessary information can be
% extracted from GRIB file itself.

\item[\bf GRIB] 
GRIdded Binary (GRIB) is the standard gridded data format from the
World Meteorological Organization (WMO).  GRIB is a general purpose,
bit-oriented data exchange format (There is no any standard GRIB API).
Most NWP centers use GRIB for all the files produced from its analyses and 
forecasts.  The GRIB format used in ESMF shall be configurable, and shall 
allow the creation of files which conform to the NCEP standard usage.  



\item[\bf IEEE Binary Streams]
A natural way for a machine to represent data is to use a native binary data 
representation. There are  two choices of ordering of 
bytes (so-called {\it Big Endian} and {\it Little Endian}), and a lot of
ambiguity in representing floating point data. The latter, however, is
specified, if IEEE Floating Point Standard 754 is satisfied 
(\cite{IEEE-Floating-Point}, \cite{Kahan-IEEE-754}). It is
desirable to be able to use efficient native representation,
accompanied by a metadata file that could be created using XML \cite{XML-W3C}. 

\item[\bf BUFR] Binary Universal Form of Represantation of the meteorological 
data (BUFR) is a self-descriptive format is a format for observational data 
transmission introduced by the World Meteorological Organization 
\cite{WMO-BUFR-CREX}. The form and content of data contained in a BUFR 
message are described within BUFR message itself. In addition, BUFR provides 
condensation, or packing of data. 

The BUFR is a table-driven code since the Data Description Section
contains a sequence of data descriptors referring to a set of
predefined and internationally agreed tables. Thus, instead of writing
all detailed definitions within a message, one will just write a
number identifying a parameter with its descriptions. The BUFR format
used in ESMF shall be configurable, and shall allow the creation of
files which conform to the NCEP standard usage, in which the
predefined tables are contained in the file.

\end{description}

Modern data management approaches could potentially provide significant 
advantages in manipulating data and have to be carefully studied.
For example, ESMWF has created and employed relational-database based 
Observational Data Base (ODB) software \cite{ODB}.  However, such complex 
data management systems are beyond the scope of the basic ESMF I/O. 


\subsection{Parallel I/O}

The future development of ESMF IO facility will require further
optimization with an expected increase in IO amount over the next few
years. Two major factors contrubuting to the increase in I/O intensity are:
\begin{description}
\item[-] Enhancement in model resolution;
\item[-] Increase in I/O frequency.
\end{description}
We also expect significant increase in amount of of satellitte data, although 
amount of I/O related to observational data is incomparable with amount of 
gridded I/O which drives our performance analysis. 

There are two aspects of  parallel IO:

\begin{description}
\item[-] How dataset distributed among multiple processors can be
written to a single file efficiently;

\item[-] How single file can be distributed accross multiple physical
discs and IO channels.
\end{description}
 
There are several possibilities to perform IO in parallel (\cite{MPI-2}):
\begin{description}
\item {\bf Single-threaded IO.} A single process acquires all the data and
writes them out. The features of hardware and OS are used to distribute the 
data over multiple chanels and, possibly, to muliple disks.

\item {\bf Multithreaded, multi-fileset IO} Many processes write to
multiple independent files. These files may be assembled later. Since each of 
the processes operates with its file logically independently, we can again 
rely on the hardware and OS to operate concurrently with multiple chanels and 
multiple disks. 
 
\item {\bf Multithreaded/Single-fileset IO.} Many processes write to a
single file. Although this approach is the most desirable one, its 
implementation is the most complicated. Since it requires concurrent access 
to the file by multiple processes, it can be implemented within the ESMF I/O 
only when such functionality is provided by underlying I/O library. 
\end{description}

Multithreaded IO offers a simple way to stripe the data accross as many
IO channels and disk channels as are available \cite{MPI-2, 
Balaji_Parallel_IO_1999, Balaji_Parallel_IO_2000}. Parallel IO implemented in 
GFDL (\cite{mpp_io}) supports parallel writing to single or multiple files. 
It supports NetCDF and binary data formats.



\subsection{Location}

Input/Output (IO) is part of the ESMF Infrastructure.  It will provide
efficient utilities to input/output gridded data and observational data
to and from the disk. A standard API will allow manipulation of multiple
standard formats.


\subsection{Scope}

ESMF IO is meant to be used for standard API and underlying implementation, 
providing input and outut of gridded data and observational data streams to 
and from the disk in multiple standard formats. I/O with different levels of 
parallelism have to be provided.  


















